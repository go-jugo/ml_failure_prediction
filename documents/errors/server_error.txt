E:\Code\venv\Scripts\python.exe E:\Code\Git\pipeline\code\main.py
E:\Programme\lib\contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
{}
2. Data merge
['../data/Buffer_Data\\export-wf2016-08-08.parquet.gzip', '../data/Buffer_Data\\export-wf2016-08-15.parquet.gzip', '../data/Buffer_Data\\export-wf2016-08-22.parquet.gzip', '../data/Buffer_Data\\export-wf2016-08-29.parquet.gzip', '../data/Buffer_Data\\export-wf2016-09-05.parquet.gzip', '../data/Buffer_Data\\export-wf2016-09-12.parquet.gzip', '../data/Buffer_Data\\export-wf2016-09-19.parquet.gzip', '../data/Buffer_Data\\export-wf2016-09-26.parquet.gzip', '../data/Buffer_Data\\export-wf2016-10-03.parquet.gzip', '../data/Buffer_Data\\export-wf2016-10-10.parquet.gzip', '../data/Buffer_Data\\export-wf2016-10-17.parquet.gzip', '../data/Buffer_Data\\export-wf2016-10-24.parquet.gzip', '../data/Buffer_Data\\export-wf2016-10-31.parquet.gzip', '../data/Buffer_Data\\export-wf2016-11-07.parquet.gzip', '../data/Buffer_Data\\export-wf2016-11-14.parquet.gzip', '../data/Buffer_Data\\export-wf2016-11-21.parquet.gzip', '../data/Buffer_Data\\export-wf2016-11-28.parquet.gzip', '../data/Buffer_Data\\export-wf2016-12-05.parquet.gzip', '../data/Buffer_Data\\export-wf2016-12-12.parquet.gzip', '../data/Buffer_Data\\export-wf2016-12-19.parquet.gzip', '../data/Buffer_Data\\export-wf2017-01-02.parquet.gzip', '../data/Buffer_Data\\export-wf2017-01-09.parquet.gzip', '../data/Buffer_Data\\export-wf2017-01-16.parquet.gzip', '../data/Buffer_Data\\export-wf2017-01-30.parquet.gzip', '../data/Buffer_Data\\export-wf2017-02-06.parquet.gzip', '../data/Buffer_Data\\export-wf2017-02-13.parquet.gzip', '../data/Buffer_Data\\export-wf2017-02-20.parquet.gzip', '../data/Buffer_Data\\export-wf2017-02-27.parquet.gzip', '../data/Buffer_Data\\export-wf2017-03-06.parquet.gzip', '../data/Buffer_Data\\export-wf2017-03-13.parquet.gzip', '../data/Buffer_Data\\export-wf2017-03-20.parquet.gzip', '../data/Buffer_Data\\export-wf2017-03-27.parquet.gzip', '../data/Buffer_Data\\export-wf2017-04-03.parquet.gzip', '../data/Buffer_Data\\export-wf2017-04-10.parquet.gzip', '../data/Buffer_Data\\export-wf2017-04-17.parquet.gzip', '../data/Buffer_Data\\export-wf2017-04-24.parquet.gzip', '../data/Buffer_Data\\export-wf2017-05-01.parquet.gzip', '../data/Buffer_Data\\export-wf2017-05-08.parquet.gzip', '../data/Buffer_Data\\export-wf2017-05-15.parquet.gzip', '../data/Buffer_Data\\export-wf2017-05-22.parquet.gzip', '../data/Buffer_Data\\export-wf2017-05-29.parquet.gzip', '../data/Buffer_Data\\export-wf2017-06-05.parquet.gzip', '../data/Buffer_Data\\export-wf2017-06-12.parquet.gzip', '../data/Buffer_Data\\export-wf2017-06-19.parquet.gzip', '../data/Buffer_Data\\export-wf2017-06-26.parquet.gzip', '../data/Buffer_Data\\export-wf2017-07-03.parquet.gzip', '../data/Buffer_Data\\export-wf2017-07-10.parquet.gzip', '../data/Buffer_Data\\export-wf2017-07-24.parquet.gzip', '../data/Buffer_Data\\export-wf2017-07-31.parquet.gzip', '../data/Buffer_Data\\export-wf2017-08-07.parquet.gzip', '../data/Buffer_Data\\export-wf2017-08-14.parquet.gzip', '../data/Buffer_Data\\export-wf2017-08-21.parquet.gzip', '../data/Buffer_Data\\export-wf2017-08-28.parquet.gzip', '../data/Buffer_Data\\export-wf2017-09-04.parquet.gzip', '../data/Buffer_Data\\export-wf2017-09-11.parquet.gzip', '../data/Buffer_Data\\export-wf2017-09-18.parquet.gzip', '../data/Buffer_Data\\export-wf2017-09-25.parquet.gzip', '../data/Buffer_Data\\export-wf2017-10-02.parquet.gzip', '../data/Buffer_Data\\export-wf2017-10-09.parquet.gzip', '../data/Buffer_Data\\export-wf2017-10-16.parquet.gzip', '../data/Buffer_Data\\export-wf2017-10-23.parquet.gzip', '../data/Buffer_Data\\export-wf2017-10-30.parquet.gzip', '../data/Buffer_Data\\export-wf2017-11-06.parquet.gzip', '../data/Buffer_Data\\export-wf2017-11-13.parquet.gzip', '../data/Buffer_Data\\export-wf2017-11-20.parquet.gzip', '../data/Buffer_Data\\export-wf2017-11-27.parquet.gzip', '../data/Buffer_Data\\export-wf2017-12-04.parquet.gzip', '../data/Buffer_Data\\export-wf2017-12-11.parquet.gzip', '../data/Buffer_Data\\export-wf2017-12-18.parquet.gzip', '../data/Buffer_Data\\export-wf2018-01-01.parquet.gzip', '../data/Buffer_Data\\export-wf2018-01-08.parquet.gzip', '../data/Buffer_Data\\export-wf2018-01-15.parquet.gzip', '../data/Buffer_Data\\export-wf2018-01-22.parquet.gzip', '../data/Buffer_Data\\export-wf2018-01-29.parquet.gzip', '../data/Buffer_Data\\export-wf2018-02-05.parquet.gzip', '../data/Buffer_Data\\export-wf2018-02-12.parquet.gzip', '../data/Buffer_Data\\export-wf2018-02-19.parquet.gzip', '../data/Buffer_Data\\export-wf2018-02-26.parquet.gzip', '../data/Buffer_Data\\export-wf2018-03-05.parquet.gzip', '../data/Buffer_Data\\export-wf2018-03-12.parquet.gzip', '../data/Buffer_Data\\export-wf2018-03-19.parquet.gzip', '../data/Buffer_Data\\export-wf2018-03-26.parquet.gzip', '../data/Buffer_Data\\export-wf2018-04-02.parquet.gzip', '../data/Buffer_Data\\export-wf2018-04-09.parquet.gzip', '../data/Buffer_Data\\export-wf2018-04-16.parquet.gzip', '../data/Buffer_Data\\export-wf2018-04-23.parquet.gzip', '../data/Buffer_Data\\export-wf2018-04-30.parquet.gzip', '../data/Buffer_Data\\export-wf2018-05-07.parquet.gzip', '../data/Buffer_Data\\export-wf2018-05-14.parquet.gzip', '../data/Buffer_Data\\export-wf2018-05-21.parquet.gzip', '../data/Buffer_Data\\export-wf2018-05-28.parquet.gzip', '../data/Buffer_Data\\export-wf2018-06-04.parquet.gzip', '../data/Buffer_Data\\export-wf2018-06-11.parquet.gzip', '../data/Buffer_Data\\export-wf2018-06-18.parquet.gzip', '../data/Buffer_Data\\export-wf2018-06-25.parquet.gzip', '../data/Buffer_Data\\export-wf2018-07-02.parquet.gzip', '../data/Buffer_Data\\export-wf2018-07-09.parquet.gzip', '../data/Buffer_Data\\export-wf2018-07-16.parquet.gzip', '../data/Buffer_Data\\export-wf2018-07-23.parquet.gzip', '../data/Buffer_Data\\export-wf2018-07-30.parquet.gzip', '../data/Buffer_Data\\export-wf2018-08-06.parquet.gzip', '../data/Buffer_Data\\export-wf2018-08-13.parquet.gzip', '../data/Buffer_Data\\export-wf2018-08-20.parquet.gzip', '../data/Buffer_Data\\export-wf2018-08-27.parquet.gzip', '../data/Buffer_Data\\export-wf2018-09-03.parquet.gzip', '../data/Buffer_Data\\export-wf2018-09-10.parquet.gzip', '../data/Buffer_Data\\export-wf2018-09-17.parquet.gzip', '../data/Buffer_Data\\export-wf2018-09-24.parquet.gzip', '../data/Buffer_Data\\export-wf2018-10-01.parquet.gzip', '../data/Buffer_Data\\export-wf2018-10-08.parquet.gzip', '../data/Buffer_Data\\export-wf2018-10-15.parquet.gzip', '../data/Buffer_Data\\export-wf2018-10-22.parquet.gzip', '../data/Buffer_Data\\export-wf2018-10-29.parquet.gzip', '../data/Buffer_Data\\export-wf2018-11-05.parquet.gzip', '../data/Buffer_Data\\export-wf2018-11-12.parquet.gzip', '../data/Buffer_Data\\export-wf2018-11-19.parquet.gzip', '../data/Buffer_Data\\export-wf2018-11-26.parquet.gzip', '../data/Buffer_Data\\export-wf2018-12-03.parquet.gzip', '../data/Buffer_Data\\export-wf2018-12-10.parquet.gzip', '../data/Buffer_Data\\export-wf2018-12-17.parquet.gzip', '../data/Buffer_Data\\export-wf2018-12-24.parquet.gzip', '../data/Buffer_Data\\export-wf2018-12-31.parquet.gzip', '../data/Buffer_Data\\export-wf2019-01-07.parquet.gzip', '../data/Buffer_Data\\export-wf2019-01-14.parquet.gzip', '../data/Buffer_Data\\export-wf2019-01-21.parquet.gzip', '../data/Buffer_Data\\export-wf2019-01-28.parquet.gzip', '../data/Buffer_Data\\export-wf2019-02-04.parquet.gzip', '../data/Buffer_Data\\export-wf2019-02-11.parquet.gzip', '../data/Buffer_Data\\export-wf2019-02-18.parquet.gzip', '../data/Buffer_Data\\export-wf2019-02-25.parquet.gzip', '../data/Buffer_Data\\export-wf2019-03-04.parquet.gzip', '../data/Buffer_Data\\export-wf2019-03-11.parquet.gzip', '../data/Buffer_Data\\export-wf2019-03-18.parquet.gzip', '../data/Buffer_Data\\export-wf2019-03-25.parquet.gzip', '../data/Buffer_Data\\export-wf2019-04-01.parquet.gzip', '../data/Buffer_Data\\export-wf2019-04-08.parquet.gzip', '../data/Buffer_Data\\export-wf2019-04-15.parquet.gzip', '../data/Buffer_Data\\export-wf2019-04-22.parquet.gzip', '../data/Buffer_Data\\export-wf2019-04-29.parquet.gzip', '../data/Buffer_Data\\export-wf2019-05-06.parquet.gzip', '../data/Buffer_Data\\export-wf2019-05-13.parquet.gzip', '../data/Buffer_Data\\export-wf2019-05-20.parquet.gzip', '../data/Buffer_Data\\export-wf2019-05-27.parquet.gzip', '../data/Buffer_Data\\export-wf2019-06-03.parquet.gzip', '../data/Buffer_Data\\export-wf2019-06-10.parquet.gzip', '../data/Buffer_Data\\export-wf2019-06-17.parquet.gzip', '../data/Buffer_Data\\export-wf2019-06-24.parquet.gzip', '../data/Buffer_Data\\export-wf2019-07-01.parquet.gzip', '../data/Buffer_Data\\export-wf2019-07-08.parquet.gzip', '../data/Buffer_Data\\export-wf2019-07-15.parquet.gzip', '../data/Buffer_Data\\export-wf2019-07-22.parquet.gzip', '../data/Buffer_Data\\export-wf2019-07-29.parquet.gzip', '../data/Buffer_Data\\export-wf2019-08-05.parquet.gzip', '../data/Buffer_Data\\export-wf2019-08-12.parquet.gzip', '../data/Buffer_Data\\export-wf2019-08-19.parquet.gzip', '../data/Buffer_Data\\export-wf2019-08-26.parquet.gzip', '../data/Buffer_Data\\export-wf2019-09-02.parquet.gzip', '../data/Buffer_Data\\export-wf2019-09-09.parquet.gzip', '../data/Buffer_Data\\export-wf2019-09-16.parquet.gzip', '../data/Buffer_Data\\export-wf2019-09-23.parquet.gzip', '../data/Buffer_Data\\export-wf2019-09-30.parquet.gzip', '../data/Buffer_Data\\export-wf2019-10-07.parquet.gzip', '../data/Buffer_Data\\export-wf2019-10-14.parquet.gzip', '../data/Buffer_Data\\export-wf2019-10-21.parquet.gzip', '../data/Buffer_Data\\export-wf2019-10-28.parquet.gzip', '../data/Buffer_Data\\export-wf2019-11-04.parquet.gzip', '../data/Buffer_Data\\export-wf2019-11-11.parquet.gzip']
2020-06-18 14:47:03 [START] create_global_dataframe
2020-06-18 14:47:08 [START] dask_repartition
Partitions 167 ... repartitioning ...
Partitions: 401
2020-06-18 14:47:39 [END] 'dask_repartition'   1 min 0.2 GB > 0.2 GB; df size:   0.0 GB
Setting index ...
2020-06-18 14:47:56 [START] dask_repartition
Partitions 401 ... repartitioning ...
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
Partitions: 401
2020-06-18 15:02:03 [END] 'dask_repartition'  14 min 0.2 GB > 0.31 GB; df size:   0.0 GB
Removing duplicates ...
2020-06-18 15:02:03 [START] dask_repartition
Partitions 401 ... repartitioning ...
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
Partitions: 401
2020-06-18 15:14:07 [END] 'dask_repartition'  12 min 0.29 GB > 0.33 GB; df size:   0.0 GB
2020-06-18 15:14:07 [END] 'create_global_dataframe'  27 min 0.11 GB > 0.33 GB; df size:   0.0 GB
3. Data cleansing
2020-06-18 15:14:07 [START] value_filter
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.000s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
2020-06-18 16:24:13 [END] 'value_filter'  70 min 0.33 GB > 0.52 GB; df size:   0.0 GB
2020-06-18 16:24:13 [START] adjust_sampling_frequency
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59530
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59530
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59530
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen
distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:59544 -> tcp://127.0.0.1:59530
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59530
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59530
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59530
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen
distributed.nanny - WARNING - Restarting worker
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59724
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 218, in connect
    _raise(error)
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 203, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://127.0.0.1:59724' after 10 s: connect() didn't finish in time

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3196, in _get_data
    comm = await rpc.connect(worker)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 894, in connect
    comm = await connect(
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 227, in connect
    _raise(error)
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 203, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://127.0.0.1:59724' after 10 s: Timed out trying to connect to 'tcp://127.0.0.1:59724' after 10 s: connect() didn't finish in time
distributed.worker - WARNING - gc.collect() took 1.531s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.266s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 4.99 GB -- Worker memory limit: 8.00 GB
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 1.594s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.worker - WARNING - gc.collect() took 1.875s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 5.30 GB -- Worker memory limit: 8.00 GB
distributed.worker - WARNING - gc.collect() took 1.047s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.worker - WARNING - gc.collect() took 1.328s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.worker - WARNING - gc.collect() took 1.422s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 1.234s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 1.641s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.000s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 1.141s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.worker - WARNING - gc.collect() took 1.938s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.250s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.547s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.359s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 1.672s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.250s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.672s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.worker - WARNING - gc.collect() took 2.594s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)
calculated partitions: 17 ... However, I use following nr of partions: 401
2020-06-18 18:22:15 [START] dask_repartition
Partitions 403 ... repartitioning ...
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.comm.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.core - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.utils - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-221990' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=MemoryError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.comm.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
SystemError: deallocated bytearray object has exported buffers
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220222' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=CompressError('Error while compressing: unable to acquire output string')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.core - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.utils - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-229465' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=MemoryError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-229475' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224419' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=MemoryError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.utils - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-b16570e5c603bd2eebf6106361636355', 195)", "('repartition-merge-3141214d6dc3728172be9479ae25cc57', 195)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-b16570e5c603bd2eebf6106361636355', 195)", "('repartition-merge-3141214d6dc3728172be9479ae25cc57', 195)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220226' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=MemoryError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 261)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 227)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-41eec13017aabf4df75188de946fd60d', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 261)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 227)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-41eec13017aabf4df75188de946fd60d', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224381' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=CompressError('Error while compressing: unable to acquire output string')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.comm.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224418' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.core - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59724
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x000000B49BA1A9D0>, <Task finished name='Task-2406' coro=<BaseTCPListener._handle_stream() done, defined at E:\Code\venv\lib\site-packages\distributed\comm\tcp.py:435> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\tcpserver.py", line 327, in <lambda>
    gen.convert_yielded(future), lambda f: f.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 444, in _handle_stream
    await self.comm_handler(comm)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 423, in handle_comm
    await comm.write(result, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.core - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 456, in handle_stream
    msgs = await comm.read()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 197, in read
    frame = bytearray(length)
MemoryError
distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 933, in handle_scheduler
    await self.handle_stream(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 456, in handle_stream
    msgs = await comm.read()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 197, in read
    frame = bytearray(length)
MemoryError
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B4F6A5FFD0>>, <Task finished name='Task-3' coro=<Worker.handle_scheduler() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:931> exception=MemoryError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 933, in handle_scheduler
    await self.handle_stream(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 456, in handle_stream
    msgs = await comm.read()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 197, in read
    frame = bytearray(length)
MemoryError
distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x000000B067EF5160>, (subgraph_callable,                        global_timestamp  ... components.cont.conditions.logic.message
global_timestamp                         ...                                         
2018-11-30 19:32:41 2018-11-30 19:32:41  ...                                      NaN
2018-11-30 19:32:47 2018-11-30 19:32:47  ...                                      NaN
2018-11-30 19:33:01 2018-11-30 19:33:01  ...                                      NaN
2018-11-30 19:33:03 2018-11-30 19:33:03  ...                                      NaN
2018-11-30 19:33:16 2018-11-30 19:33:16  ...                                      NaN
...                                 ...  ...                                      ...
2018-12-04 14:24:37 2018-12-04 14:24:37  ...                                      NaN
2018-12-04 14:24:38 2018-12-04 14:24:38  ...                                      NaN
2018-12-04 14:24:42 2018-12-04 14:24:42  ...                         
kwargs:    {}
Exception: MemoryError((10, 41897), dtype('O'))

distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x0000001F7A895160>, (subgraph_callable,                        global_timestamp  ... components.cont.conditions.logic.message
global_timestamp                         ...                                         
2018-06-07 20:55:45 2018-06-07 20:55:45  ...                                      NaN
2018-06-07 20:55:46 2018-06-07 20:55:46  ...                                      NaN
2018-06-07 20:55:50 2018-06-07 20:55:50  ...                                      NaN
2018-06-07 20:55:53 2018-06-07 20:55:53  ...                                      NaN
2018-06-07 20:55:57 2018-06-07 20:55:57  ...                                      NaN
...                                 ...  ...                                      ...
2018-06-11 10:21:19 2018-06-11 10:21:19  ...                                      NaN
2018-06-11 10:21:28 2018-06-11 10:21:28  ...                                      NaN
2018-06-11 10:21:30 2018-06-11 10:21:30  ...                         
kwargs:    {}
Exception: MemoryError((10, 41897), dtype('O'))

distributed.worker - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x000000157FF75160>, (subgraph_callable,                        global_timestamp  ... components.cont.conditions.logic.message
global_timestamp                         ...                                         
2017-09-20 09:20:45 2017-09-20 09:20:45  ...                                      NaN
2017-09-20 09:20:51 2017-09-20 09:20:51  ...                                      NaN
2017-09-20 09:20:53 2017-09-20 09:20:53  ...                                      NaN
2017-09-20 09:20:55 2017-09-20 09:20:55  ...                                      NaN
2017-09-20 09:20:56 2017-09-20 09:20:56  ...                                      NaN
...                                 ...  ...                                      ...
2017-09-21 19:00:50 2017-09-21 19:00:50  ...                                      NaN
2017-09-21 19:00:52 2017-09-21 19:00:52  ...                                      NaN
2017-09-21 19:00:56 2017-09-21 19:00:56  ...                         
kwargs:    {}
Exception: MemoryError((10, 41897), dtype('O'))

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-b16570e5c603bd2eebf6106361636355', 195)", "('repartition-merge-3141214d6dc3728172be9479ae25cc57', 195)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-b16570e5c603bd2eebf6106361636355', 195)", "('repartition-merge-3141214d6dc3728172be9479ae25cc57', 195)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x00000059533F5160>, (subgraph_callable,                        global_timestamp  ... components.hydraulic.conditions.hyd.errorCode
global_timestamp                         ...                                              
2017-04-28 22:00:13 2017-04-28 22:00:13  ...                                           NaN
2017-04-28 22:00:17 2017-04-28 22:00:17  ...                                           NaN
2017-04-28 22:00:18 2017-04-28 22:00:18  ...                                           NaN
2017-04-28 22:00:25 2017-04-28 22:00:25  ...                                           NaN
2017-04-28 22:00:27 2017-04-28 22:00:27  ...                                           NaN
...                                 ...  ...                                           ...
2017-05-04 15:04:50 2017-05-04 15:04:50  ...                                           NaN
2017-05-04 15:04:52 2017-05-04 15:04:52  ...                                           NaN
2017-05-04 15:04:55
kwargs:    {}
Exception: MemoryError((18, 41897), dtype('O'))

distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-b16570e5c603bd2eebf6106361636355', 195)", "('repartition-merge-3141214d6dc3728172be9479ae25cc57', 195)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-b16570e5c603bd2eebf6106361636355', 195)", "('repartition-merge-3141214d6dc3728172be9479ae25cc57', 195)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.comm.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222025' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-b16570e5c603bd2eebf6106361636355', 195)", "('repartition-merge-3141214d6dc3728172be9479ae25cc57', 195)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-b16570e5c603bd2eebf6106361636355', 195)", "('repartition-merge-3141214d6dc3728172be9479ae25cc57', 195)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.core - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220254' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=CompressError('Error while compressing: unable to acquire output string')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220273' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-229498' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 29)", "('repartition-merge-147a0b164676b234d0325191d9ca0b6e', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 29)", "('repartition-merge-147a0b164676b234d0325191d9ca0b6e', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x0000001F7A895160>, (subgraph_callable,                        global_timestamp  ... components.c2.samples.cso2.value
global_timestamp                         ...                                 
2017-09-21 19:01:07 2017-09-21 19:01:07  ...                              NaN
2017-09-21 19:01:08 2017-09-21 19:01:08  ...                              NaN
2017-09-21 19:01:09 2017-09-21 19:01:09  ...                              NaN
2017-09-21 19:01:10 2017-09-21 19:01:10  ...                              NaN
2017-09-21 19:01:12 2017-09-21 19:01:12  ...                              NaN
...                                 ...  ...                              ...
2017-09-25 21:44:31 2017-09-25 21:44:31  ...                              NaN
2017-09-25 21:44:35 2017-09-25 21:44:35  ...                              NaN
2017-09-25 21:44:40 2017-09-25 21:44:40  ...                              NaN
2017-09-25 21:44:41 2017-09-25 21:44:41  ...                           
kwargs:    {}
Exception: MemoryError((5, 41897), dtype('O'))

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220275' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 29)", "('repartition-merge-147a0b164676b234d0325191d9ca0b6e', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 29)", "('repartition-merge-147a0b164676b234d0325191d9ca0b6e', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 29)", "('repartition-merge-147a0b164676b234d0325191d9ca0b6e', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 29)", "('repartition-merge-147a0b164676b234d0325191d9ca0b6e', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-229534' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 29)", "('repartition-merge-147a0b164676b234d0325191d9ca0b6e', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 29)", "('repartition-merge-147a0b164676b234d0325191d9ca0b6e', 184)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
MemoryError
distributed.worker - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224432' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=CompressError('Error while compressing: unable to acquire output string')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
MemoryError
distributed.utils - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
MemoryError
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x00000020FED25160>, (subgraph_callable,                        global_timestamp  ... components.path1.events.exec.state
global_timestamp                         ...                                   
2019-06-18 21:28:32 2019-06-18 21:28:32  ...                                NaN
2019-06-18 21:28:34 2019-06-18 21:28:34  ...                                NaN
2019-06-18 21:28:40 2019-06-18 21:28:40  ...                                NaN
2019-06-18 21:28:42 2019-06-18 21:28:42  ...                                NaN
2019-06-18 21:28:45 2019-06-18 21:28:45  ...                                NaN
...                                 ...  ...                                ...
2019-06-20 18:27:52 2019-06-20 18:27:52  ...                                NaN
2019-06-20 18:27:53 2019-06-20 18:27:53  ...                                NaN
2019-06-20 18:27:54 2019-06-20 18:27:54  ...                                NaN
2019-06-20 18:27:55 2019-06-20 18:27:55  ...     
kwargs:    {}
Exception: MemoryError((20, 41897), dtype('O'))

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-cdd3819b950f5559ced83a66e39da9c9', 86)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 333)", "('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 394)", "('repartition-merge-392dd5694aa0a1da67c51d67820c7cf0', 204)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-cdd3819b950f5559ced83a66e39da9c9', 86)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 333)", "('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 394)", "('repartition-merge-392dd5694aa0a1da67c51d67820c7cf0', 204)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.utils - ERROR - __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224493' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError("__init__() missing 2 required positional arguments: 'shape' and 'dtype'")>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222086' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222083' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x00000059533F5160>, (subgraph_callable,                        global_timestamp  ... components.path1.samples.atime.value
global_timestamp                         ...                                     
2017-06-16 00:35:06 2017-06-16 00:35:06  ...                                  NaN
2017-06-16 00:35:08 2017-06-16 00:35:08  ...                                  NaN
2017-06-16 00:35:10 2017-06-16 00:35:10  ...                                  NaN
2017-06-16 00:35:11 2017-06-16 00:35:11  ...                                  NaN
2017-06-16 00:35:12 2017-06-16 00:35:12  ...                                  NaN
...                                 ...  ...                                  ...
2017-06-19 06:35:44 2017-06-19 06:35:44  ...                                  NaN
2017-06-19 06:35:45 2017-06-19 06:35:45  ...                                  NaN
2017-06-19 06:35:46 2017-06-19 06:35:46  ...                                  NaN
2017-06-19 06:35:47 2017-06
kwargs:    {}
Exception: MemoryError((24, 41897), dtype('float64'))

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-cdd3819b950f5559ced83a66e39da9c9', 86)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 333)", "('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 394)", "('repartition-merge-392dd5694aa0a1da67c51d67820c7cf0', 204)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-cdd3819b950f5559ced83a66e39da9c9', 86)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 333)", "('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 394)", "('repartition-merge-392dd5694aa0a1da67c51d67820c7cf0', 204)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-cdd3819b950f5559ced83a66e39da9c9', 86)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 333)", "('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 394)", "('repartition-merge-392dd5694aa0a1da67c51d67820c7cf0', 204)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-cdd3819b950f5559ced83a66e39da9c9', 86)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 333)", "('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 394)", "('repartition-merge-392dd5694aa0a1da67c51d67820c7cf0', 204)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-229494' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224439' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-cdd3819b950f5559ced83a66e39da9c9', 86)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 333)", "('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 394)", "('repartition-merge-392dd5694aa0a1da67c51d67820c7cf0', 204)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-cdd3819b950f5559ced83a66e39da9c9', 86)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 333)", "('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 394)", "('repartition-merge-392dd5694aa0a1da67c51d67820c7cf0', 204)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.comm.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.core - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-230381' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000157D56FFD0>>, <Task finished name='Task-217575' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=MemoryError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
MemoryError
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222088' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-099f6b34bbb249cd8d29ef1109bf2490', 394)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-099f6b34bbb249cd8d29ef1109bf2490', 394)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-7664d10f42ec8210fff4d40037bd8c23', 82)", "('repartition-merge-2f6f09a66370c5d8036bf7683e03c82a', 82)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 228)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-7664d10f42ec8210fff4d40037bd8c23', 82)", "('repartition-merge-2f6f09a66370c5d8036bf7683e03c82a', 82)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 228)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x00000020FED25160>, (subgraph_callable,                        global_timestamp  ... components.path1.events.seq.state
global_timestamp                         ...                                  
2018-02-14 09:32:37 2018-02-14 09:32:37  ...                               NaN
2018-02-14 09:32:44 2018-02-14 09:32:44  ...                               NaN
2018-02-14 09:32:45 2018-02-14 09:32:45  ...                               NaN
2018-02-14 09:32:46 2018-02-14 09:32:46  ...                               NaN
2018-02-14 09:32:53 2018-02-14 09:32:53  ...                               NaN
...                                 ...  ...                               ...
2018-02-15 21:30:07 2018-02-15 21:30:07  ...                               NaN
2018-02-15 21:30:08 2018-02-15 21:30:08  ...                               NaN
2018-02-15 21:30:11 2018-02-15 21:30:11  ...                               NaN
2018-02-15 21:30:12 2018-02-15 21:30:12  ...                
kwargs:    {}
Exception: MemoryError((26, 41897), dtype('O'))

distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-14679a0db1385ce83baed2a9bc76e9fb', 29)", "('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-14679a0db1385ce83baed2a9bc76e9fb', 29)", "('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-14679a0db1385ce83baed2a9bc76e9fb', 29)", "('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-14679a0db1385ce83baed2a9bc76e9fb', 29)", "('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-14679a0db1385ce83baed2a9bc76e9fb', 29)", "('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-14679a0db1385ce83baed2a9bc76e9fb', 29)", "('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
MemoryError
distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
MemoryError
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-230377' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-14679a0db1385ce83baed2a9bc76e9fb', 29)", "('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0cdd5d27a2bb778edbd135570d82edec', 391)", "('repartition-merge-14679a0db1385ce83baed2a9bc76e9fb', 29)", "('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-099f6b34bbb249cd8d29ef1109bf2490', 394)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-099f6b34bbb249cd8d29ef1109bf2490', 394)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-099f6b34bbb249cd8d29ef1109bf2490', 394)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-099f6b34bbb249cd8d29ef1109bf2490', 394)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
MemoryError
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)",), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)",), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)",), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)",), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)",), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)",), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-230889' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)",), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 370)",), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B4F6A5FFD0>>, <Task finished name='Task-136701' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=CommClosedError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2036, in gather_dep
    self.batched_stream.send(
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224521' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-099f6b34bbb249cd8d29ef1109bf2490', 394)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-e1a570b724c9bac0dc62f5681396779c', 81)", "('repartition-merge-099f6b34bbb249cd8d29ef1109bf2490', 394)"), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222080' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=CompressError('Error while compressing: unable to acquire output string')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222087' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

SystemErrortornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x00000020F959FFD0>>, <Task finished name='Task-222955' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=MemoryError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
MemoryError
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

: deallocated bytearray object has exported buffers
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-774e083a0cf67426830cc0e6d2ffba34', 279)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 344)", "('repartition-merge-162815cf1c36272611f38a10d906c11c', 96)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 279)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-774e083a0cf67426830cc0e6d2ffba34', 279)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 344)", "('repartition-merge-162815cf1c36272611f38a10d906c11c', 96)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 279)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.utils - ERROR - 
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000157D56FFD0>>, <Task finished name='Task-217537' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=MemoryError()>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 62, in pickle_loads
    return pickle.loads(b"".join(frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 59, in loads
    return pickle.loads(x)
MemoryError
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224531' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-774e083a0cf67426830cc0e6d2ffba34', 279)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 344)", "('repartition-merge-162815cf1c36272611f38a10d906c11c', 96)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 279)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-774e083a0cf67426830cc0e6d2ffba34', 279)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 344)", "('repartition-merge-162815cf1c36272611f38a10d906c11c', 96)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 279)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-774e083a0cf67426830cc0e6d2ffba34', 279)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 344)", "('repartition-merge-162815cf1c36272611f38a10d906c11c', 96)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 279)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-774e083a0cf67426830cc0e6d2ffba34', 279)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 344)", "('repartition-merge-162815cf1c36272611f38a10d906c11c', 96)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 279)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-230380' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-774e083a0cf67426830cc0e6d2ffba34', 279)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 344)", "('repartition-merge-162815cf1c36272611f38a10d906c11c', 96)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 279)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-774e083a0cf67426830cc0e6d2ffba34', 279)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 344)", "('repartition-merge-162815cf1c36272611f38a10d906c11c', 96)", "('repartition-merge-b85f6c81ff9edd107a96796184aa42d6', 358)", "('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 279)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-7664d10f42ec8210fff4d40037bd8c23', 82)", "('repartition-merge-2f6f09a66370c5d8036bf7683e03c82a', 82)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 228)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-7664d10f42ec8210fff4d40037bd8c23', 82)", "('repartition-merge-2f6f09a66370c5d8036bf7683e03c82a', 82)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 228)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-7664d10f42ec8210fff4d40037bd8c23', 82)", "('repartition-merge-2f6f09a66370c5d8036bf7683e03c82a', 82)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 228)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-7664d10f42ec8210fff4d40037bd8c23', 82)", "('repartition-merge-2f6f09a66370c5d8036bf7683e03c82a', 82)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 228)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-41eec13017aabf4df75188de946fd60d', 250)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 189)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-41eec13017aabf4df75188de946fd60d', 250)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 189)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222110' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-7664d10f42ec8210fff4d40037bd8c23', 82)", "('repartition-merge-2f6f09a66370c5d8036bf7683e03c82a', 82)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 228)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-7664d10f42ec8210fff4d40037bd8c23', 82)", "('repartition-merge-2f6f09a66370c5d8036bf7683e03c82a', 82)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 228)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 281)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 90)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 216)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 148)", "('repartition-merge-d334b5a481360cd5cfc6d629ec3a3d18', 332)", "('repartition-merge-678a82762d606b2a7f4a6bbdce437989', 164)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-85d19cf06b88f32003a4a46a5c899e80', 180)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 281)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 90)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 216)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 148)", "('repartition-merge-d334b5a481360cd5cfc6d629ec3a3d18', 332)", "('repartition-merge-678a82762d606b2a7f4a6bbdce437989', 164)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-85d19cf06b88f32003a4a46a5c899e80', 180)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x00000020F959FFD0>>, <Task finished name='Task-223037' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x00000020F959FFD0>>, <Task finished name='Task-223036' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222024' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-41eec13017aabf4df75188de946fd60d', 250)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 189)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-41eec13017aabf4df75188de946fd60d', 250)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 189)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-41eec13017aabf4df75188de946fd60d', 250)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 189)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-41eec13017aabf4df75188de946fd60d', 250)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 189)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-3141214d6dc3728172be9479ae25cc57', 111)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-3141214d6dc3728172be9479ae25cc57', 111)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-3141214d6dc3728172be9479ae25cc57', 111)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-3141214d6dc3728172be9479ae25cc57', 111)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-3141214d6dc3728172be9479ae25cc57', 111)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-3141214d6dc3728172be9479ae25cc57', 111)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x00000020F959FFD0>>, <Task finished name='Task-223069' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-3141214d6dc3728172be9479ae25cc57', 111)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-3141214d6dc3728172be9479ae25cc57', 111)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.comm.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.core - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-050c5bfd44512b566c89165dcf38719e', 46)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 188)"), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-050c5bfd44512b566c89165dcf38719e', 46)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 188)"), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222119' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-41eec13017aabf4df75188de946fd60d', 250)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 189)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-41eec13017aabf4df75188de946fd60d', 250)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 189)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000B04A76FFD0>>, <Task finished name='Task-222131' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-230890' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Handle missing dep failed, retrying
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.utils - ERROR - Error while compressing: unable to acquire output string
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220253' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=CompressError('Error while compressing: unable to acquire output string')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 58, in dumps
    compression, frames = zip(*map(maybe_compress, frames))
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 202, in maybe_compress
    compressed = compress(ensure_bytes(payload))
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 85, in compress
    return _compress(data)
snappy.CompressError: Error while compressing: unable to acquire output string
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 281)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 90)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 216)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 148)", "('repartition-merge-d334b5a481360cd5cfc6d629ec3a3d18', 332)", "('repartition-merge-678a82762d606b2a7f4a6bbdce437989', 164)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-85d19cf06b88f32003a4a46a5c899e80', 180)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 281)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 90)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 216)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 148)", "('repartition-merge-d334b5a481360cd5cfc6d629ec3a3d18', 332)", "('repartition-merge-678a82762d606b2a7f4a6bbdce437989', 164)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-85d19cf06b88f32003a4a46a5c899e80', 180)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-229473' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224533' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-050c5bfd44512b566c89165dcf38719e', 46)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 188)"), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-050c5bfd44512b566c89165dcf38719e', 46)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 188)"), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-050c5bfd44512b566c89165dcf38719e', 46)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 188)"), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-050c5bfd44512b566c89165dcf38719e', 46)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 188)"), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x00000020F959FFD0>>, <Task finished name='Task-223064' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-050c5bfd44512b566c89165dcf38719e', 46)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 188)"), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-050c5bfd44512b566c89165dcf38719e', 46)", "('repartition-merge-a9713e46471289cb8bae3fe8e38da5de', 188)"), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 281)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 90)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 216)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 148)", "('repartition-merge-d334b5a481360cd5cfc6d629ec3a3d18', 332)", "('repartition-merge-678a82762d606b2a7f4a6bbdce437989', 164)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-85d19cf06b88f32003a4a46a5c899e80', 180)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 281)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 90)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 216)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 148)", "('repartition-merge-d334b5a481360cd5cfc6d629ec3a3d18', 332)", "('repartition-merge-678a82762d606b2a7f4a6bbdce437989', 164)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-85d19cf06b88f32003a4a46a5c899e80', 180)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000157D56FFD0>>, <Task finished name='Task-217606' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 365)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 365)",), 'who': 'tcp://127.0.0.1:59531', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-1918334bc0d6788c3608fb760856efb1', 255)", "('repartition-merge-897999124fc6ff5ccd3188513f62de94', 107)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-1918334bc0d6788c3608fb760856efb1', 255)", "('repartition-merge-897999124fc6ff5ccd3188513f62de94', 107)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: <lambda>() takes 1 positional argument but 2 were given
distributed.comm.utils - ERROR - <lambda>() takes 1 positional argument but 2 were given
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: <lambda>() takes 1 positional argument but 2 were given
distributed.worker - ERROR - <lambda>() takes 1 positional argument but 2 were given
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: <lambda>() takes 1 positional argument but 2 were given
distributed.utils - ERROR - <lambda>() takes 1 positional argument but 2 were given
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: <lambda>() takes 1 positional argument but 2 were given
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220375' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('<lambda>() takes 1 positional argument but 2 were given')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: <lambda>() takes 1 positional argument but 2 were given
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-1918334bc0d6788c3608fb760856efb1', 255)", "('repartition-merge-897999124fc6ff5ccd3188513f62de94', 107)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-1918334bc0d6788c3608fb760856efb1', 255)", "('repartition-merge-897999124fc6ff5ccd3188513f62de94', 107)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-1918334bc0d6788c3608fb760856efb1', 255)", "('repartition-merge-897999124fc6ff5ccd3188513f62de94', 107)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-1918334bc0d6788c3608fb760856efb1', 255)", "('repartition-merge-897999124fc6ff5ccd3188513f62de94', 107)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220374' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-1918334bc0d6788c3608fb760856efb1', 255)", "('repartition-merge-897999124fc6ff5ccd3188513f62de94', 107)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-1918334bc0d6788c3608fb760856efb1', 255)", "('repartition-merge-897999124fc6ff5ccd3188513f62de94', 107)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224764' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000157D56FFD0>>, <Task finished name='Task-217605' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 281)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 90)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 216)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 148)", "('repartition-merge-d334b5a481360cd5cfc6d629ec3a3d18', 332)", "('repartition-merge-678a82762d606b2a7f4a6bbdce437989', 164)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-85d19cf06b88f32003a4a46a5c899e80', 180)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-1d9362f30f63ada9db357c7f37ebfa9f', 281)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 90)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 216)", "('repartition-merge-3e5831b5f15ab11f6e1cd5f14590ddb6', 148)", "('repartition-merge-d334b5a481360cd5cfc6d629ec3a3d18', 332)", "('repartition-merge-678a82762d606b2a7f4a6bbdce437989', 164)", "('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-85d19cf06b88f32003a4a46a5c899e80', 180)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x00000015375E19D0>, <Task finished name='Task-1832' coro=<BaseTCPListener._handle_stream() done, defined at E:\Code\venv\lib\site-packages\distributed\comm\tcp.py:435> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\tcpserver.py", line 327, in <lambda>
    gen.convert_yielded(future), lambda f: f.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 444, in _handle_stream
    await self.comm_handler(comm)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 423, in handle_comm
    await comm.write(result, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-241170' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nTypeError: __init__() missing 2 required positional arguments: \'shape\' and \'dtype\'\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'

distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:59534
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-857a55baa24c18a7c6ddf56816a42454', 231)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 189)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 58)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-857a55baa24c18a7c6ddf56816a42454', 231)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 189)", "('repartition-merge-050c5bfd44512b566c89165dcf38719e', 58)"), 'who': 'tcp://127.0.0.1:59536', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 138)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 96)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 138)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 96)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 104)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 104)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 138)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 96)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 138)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 96)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 138)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 96)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 138)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 96)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 104)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 104)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 104)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 104)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-241175' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 138)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 96)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-ff5a49f05c8dc8f19fda0c345bcc1dda', 138)", "('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 96)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224779' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 104)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-0022d3bb228a673a3a3b4d42e918423b', 104)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-4a6f8b63a57140d269a58eba72950cf7', 86)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-4a6f8b63a57140d269a58eba72950cf7', 86)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-4a6f8b63a57140d269a58eba72950cf7', 86)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-4a6f8b63a57140d269a58eba72950cf7', 86)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-4a6f8b63a57140d269a58eba72950cf7', 86)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-4a6f8b63a57140d269a58eba72950cf7', 86)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224762' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-4a6f8b63a57140d269a58eba72950cf7', 86)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-4a6f8b63a57140d269a58eba72950cf7', 86)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 178)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 178)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 178)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 178)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 178)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 178)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224809' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 178)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-07b79af7d2ca28294b7bd7474fa914ee', 178)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-9f3e240f8234da106ae3ce7cb35b2d92', 180)",), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-9f3e240f8234da106ae3ce7cb35b2d92', 180)",), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: __init__() missing 1 required positional argument: 'dtype'
distributed.comm.utils - ERROR - __init__() missing 1 required positional argument: 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: __init__() missing 1 required positional argument: 'dtype'
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 335)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 335)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x00000020F959FFD0>>, <Task finished name='Task-223088' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220388' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 335)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 335)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 335)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 335)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-241172' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 335)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 344)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 335)"), 'who': 'tcp://127.0.0.1:59527', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-9f3e240f8234da106ae3ce7cb35b2d92', 180)",), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-9f3e240f8234da106ae3ce7cb35b2d92', 180)",), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-9f3e240f8234da106ae3ce7cb35b2d92', 180)",), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-9f3e240f8234da106ae3ce7cb35b2d92', 180)",), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000157D56FFD0>>, <Task finished name='Task-217640' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-9f3e240f8234da106ae3ce7cb35b2d92', 180)",), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-9f3e240f8234da106ae3ce7cb35b2d92', 180)",), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
distributed.batched - ERROR - Error in batched write
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 92, in _background_send
    nbytes = yield self.comm.write(
  File "E:\Code\venv\lib\site-packages\tornado\gen.py", line 735, in run
    value = future.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: __init__() missing 1 required positional argument: 'dtype'
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 140)", "('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 140)", "('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.worker - ERROR - __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.utils - ERROR - __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224816' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError("__init__() missing 2 required positional arguments: 'shape' and 'dtype'")>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.worker - ERROR - __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.utils - ERROR - __init__() missing 2 required positional arguments: 'shape' and 'dtype'
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 140)", "('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 140)", "('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 140)", "('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 140)", "('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220407' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 140)", "('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-455e391f7496bb9246d6cf0498907c85', 140)", "('repartition-merge-2366a2053207f901ba077d6e708ad3e4', 153)", "('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.worker - WARNING -  Compute Failed
Function:  execute_task
args:      ((<function boundary_slice at 0x00000059533F5160>, (subgraph_callable,                        global_timestamp  ... components.path1.samples.pfo.value
global_timestamp                         ...                                   
2019-07-30 08:56:05 2019-07-30 08:56:05  ...                                NaN
2019-07-30 08:56:12 2019-07-30 08:56:12  ...                                NaN
2019-07-30 08:56:14 2019-07-30 08:56:14  ...                                NaN
2019-07-30 08:56:15 2019-07-30 08:56:15  ...                                NaN
2019-07-30 08:56:18 2019-07-30 08:56:18  ...                                NaN
...                                 ...  ...                                ...
2019-08-01 00:14:29 2019-08-01 00:14:29  ...                                NaN
2019-08-01 00:14:30 2019-08-01 00:14:30  ...                                0.0
2019-08-01 00:14:32 2019-08-01 00:14:32  ...                                NaN
2019-08-01 00:14:41 2019-08-01 00:14:41  ...     
kwargs:    {}
Exception: MemoryError((27, 41897), dtype('float64'))

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000005935C6FFD0>>, <Task finished name='Task-224819' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError("__init__() missing 2 required positional arguments: 'shape' and 'dtype'")>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 122, in loads
    fs = decompress(head, fs)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 212, in decompress
    return [
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 213, in <listcomp>
    compressions[c]["decompress"](frame)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\compression.py", line 47, in _fixed_snappy_decompress
    return snappy.decompress(data)
  File "E:\Code\venv\lib\site-packages\snappy\snappy.py", line 92, in uncompress
    return _uncompress(data)
TypeError: __init__() missing 2 required positional arguments: 'shape' and 'dtype'
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-de6769a01bb48e904fa40464e0aa9003', 206)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-de6769a01bb48e904fa40464e0aa9003', 206)",), 'who': 'tcp://127.0.0.1:59526', 'max_connections': None, 'reply': True}
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220414' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-f3c328cd1e17bc93e49827a5bd523473', 140)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220416' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-ff869e017f93cb7198f99c5103eb1de2', 323)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-ff869e017f93cb7198f99c5103eb1de2', 323)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220705' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-ff869e017f93cb7198f99c5103eb1de2', 323)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-ff869e017f93cb7198f99c5103eb1de2', 323)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-ff869e017f93cb7198f99c5103eb1de2', 323)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-ff869e017f93cb7198f99c5103eb1de2', 323)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220703' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-ff869e017f93cb7198f99c5103eb1de2', 323)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-ff869e017f93cb7198f99c5103eb1de2', 323)",), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220658' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-fb05d805f5694b898f1d792f77d8d3b9', 6)", "('repartition-merge-34f2af0ef821c11735273f4cb922e2c8', 362)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 89)", "('repartition-merge-a7ff994af69fd565c6e6eb0dfef39777', 33)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 89)", "('repartition-merge-1d5105d1d9ef45b9d57fcd94cb52e4f7', 99)", "('repartition-merge-a176c8af54ced0760fe2352c715ee54e', 6)", "('repartition-merge-e89ffe71bd2b5e5b42a183bc0f8b8d82', 241)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-fb05d805f5694b898f1d792f77d8d3b9', 6)", "('repartition-merge-34f2af0ef821c11735273f4cb922e2c8', 362)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 89)", "('repartition-merge-a7ff994af69fd565c6e6eb0dfef39777', 33)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 89)", "('repartition-merge-1d5105d1d9ef45b9d57fcd94cb52e4f7', 99)", "('repartition-merge-a176c8af54ced0760fe2352c715ee54e', 6)", "('repartition-merge-e89ffe71bd2b5e5b42a183bc0f8b8d82', 241)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220771' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-fb05d805f5694b898f1d792f77d8d3b9', 6)", "('repartition-merge-34f2af0ef821c11735273f4cb922e2c8', 362)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 89)", "('repartition-merge-a7ff994af69fd565c6e6eb0dfef39777', 33)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 89)", "('repartition-merge-1d5105d1d9ef45b9d57fcd94cb52e4f7', 99)", "('repartition-merge-a176c8af54ced0760fe2352c715ee54e', 6)", "('repartition-merge-e89ffe71bd2b5e5b42a183bc0f8b8d82', 241)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-fb05d805f5694b898f1d792f77d8d3b9', 6)", "('repartition-merge-34f2af0ef821c11735273f4cb922e2c8', 362)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 89)", "('repartition-merge-a7ff994af69fd565c6e6eb0dfef39777', 33)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 89)", "('repartition-merge-1d5105d1d9ef45b9d57fcd94cb52e4f7', 99)", "('repartition-merge-a176c8af54ced0760fe2352c715ee54e', 6)", "('repartition-merge-e89ffe71bd2b5e5b42a183bc0f8b8d82', 241)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-fb05d805f5694b898f1d792f77d8d3b9', 6)", "('repartition-merge-34f2af0ef821c11735273f4cb922e2c8', 362)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 89)", "('repartition-merge-a7ff994af69fd565c6e6eb0dfef39777', 33)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 89)", "('repartition-merge-1d5105d1d9ef45b9d57fcd94cb52e4f7', 99)", "('repartition-merge-a176c8af54ced0760fe2352c715ee54e', 6)", "('repartition-merge-e89ffe71bd2b5e5b42a183bc0f8b8d82', 241)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-fb05d805f5694b898f1d792f77d8d3b9', 6)", "('repartition-merge-34f2af0ef821c11735273f4cb922e2c8', 362)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 89)", "('repartition-merge-a7ff994af69fd565c6e6eb0dfef39777', 33)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 89)", "('repartition-merge-1d5105d1d9ef45b9d57fcd94cb52e4f7', 99)", "('repartition-merge-a176c8af54ced0760fe2352c715ee54e', 6)", "('repartition-merge-e89ffe71bd2b5e5b42a183bc0f8b8d82', 241)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x0000001F5D10FFD0>>, <Task finished name='Task-220774' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-fb05d805f5694b898f1d792f77d8d3b9', 6)", "('repartition-merge-34f2af0ef821c11735273f4cb922e2c8', 362)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 89)", "('repartition-merge-a7ff994af69fd565c6e6eb0dfef39777', 33)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 89)", "('repartition-merge-1d5105d1d9ef45b9d57fcd94cb52e4f7', 99)", "('repartition-merge-a176c8af54ced0760fe2352c715ee54e', 6)", "('repartition-merge-e89ffe71bd2b5e5b42a183bc0f8b8d82', 241)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-fb05d805f5694b898f1d792f77d8d3b9', 6)", "('repartition-merge-34f2af0ef821c11735273f4cb922e2c8', 362)", "('repartition-merge-7d58bb76561a11304754e8db67f6c6ea', 89)", "('repartition-merge-a7ff994af69fd565c6e6eb0dfef39777', 33)", "('repartition-merge-277860e66ad134693627a24cdffb7728', 89)", "('repartition-merge-1d5105d1d9ef45b9d57fcd94cb52e4f7', 99)", "('repartition-merge-a176c8af54ced0760fe2352c715ee54e', 6)", "('repartition-merge-e89ffe71bd2b5e5b42a183bc0f8b8d82', 241)"), 'who': 'tcp://127.0.0.1:59544', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x000000B49891A8B0>
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 907, in _run
    return self.callback()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 654, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.batched - ERROR - Error in batched write
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 92, in _background_send
    nbytes = yield self.comm.write(
  File "E:\Code\venv\lib\site-packages\tornado\gen.py", line 735, in run
    value = future.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.batched - ERROR - Error in batched write
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 92, in _background_send
    nbytes = yield self.comm.write(
  File "E:\Code\venv\lib\site-packages\tornado\gen.py", line 735, in run
    value = future.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x000000B49891A8B0>
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 907, in _run
    return self.callback()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 654, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: send_recv_from_rpc() takes 0 positional arguments but 2 were given
distributed.comm.utils - ERROR - send_recv_from_rpc() takes 0 positional arguments but 2 were given
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: send_recv_from_rpc() takes 0 positional arguments but 2 were given
distributed.batched - ERROR - Error in batched write
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 92, in _background_send
    nbytes = yield self.comm.write(
  File "E:\Code\venv\lib\site-packages\tornado\gen.py", line 735, in run
    value = future.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
TypeError: send_recv_from_rpc() takes 0 positional arguments but 2 were given
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - Handle missing dep failed, retrying
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - Handle missing dep failed, retrying
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.batched - ERROR - Error in batched write
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 92, in _background_send
    nbytes = yield self.comm.write(
  File "E:\Code\venv\lib\site-packages\tornado\gen.py", line 735, in run
    value = future.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x0000009718B63790>, <Task finished name='Task-151289' coro=<BaseTCPListener._handle_stream() done, defined at E:\Code\venv\lib\site-packages\distributed\comm\tcp.py:435> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\tcpserver.py", line 327, in <lambda>
    gen.convert_yielded(future), lambda f: f.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 444, in _handle_stream
    await self.comm_handler(comm)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 423, in handle_comm
    await comm.write(result, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x000000970C3AFC10>, <Task finished name='Task-60358' coro=<BaseTCPListener._handle_stream() done, defined at E:\Code\venv\lib\site-packages\distributed\comm\tcp.py:435> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\tcpserver.py", line 327, in <lambda>
    gen.convert_yielded(future), lambda f: f.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 444, in _handle_stream
    await self.comm_handler(comm)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 423, in handle_comm
    await comm.write(result, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x000000970E4705E0>, <Task finished name='Task-60230' coro=<BaseTCPListener._handle_stream() done, defined at E:\Code\venv\lib\site-packages\distributed\comm\tcp.py:435> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\tcpserver.py", line 327, in <lambda>
    gen.convert_yielded(future), lambda f: f.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 444, in _handle_stream
    await self.comm_handler(comm)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 423, in handle_comm
    await comm.write(result, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - Handle missing dep failed, retrying
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - Handle missing dep failed, retrying
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - Handle missing dep failed, retrying
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - Handle missing dep failed, retrying
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.comm.utils - ERROR - Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.worker - ERROR - Handle missing dep failed, retrying
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000F9D645FFD0>>, <Task finished name='Task-229531' coro=<Worker.handle_missing_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:2066> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2109, in handle_missing_dep
    await self.handle_missing_dep(self, *deps, retries=retries - 1)
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2109, in handle_missing_dep
    await self.handle_missing_dep(self, *deps, retries=retries - 1)
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2109, in handle_missing_dep
    await self.handle_missing_dep(self, *deps, retries=retries - 1)
  [Previous line repeated 2 more times]
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 2089, in handle_missing_dep
    who_has = await retry_operation(self.scheduler.who_has, keys=list(deps))
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
distributed.batched - ERROR - Error in batched write
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\batched.py", line 92, in _background_send
    nbytes = yield self.comm.write(
  File "E:\Code\venv\lib\site-packages\tornado\gen.py", line 735, in run
    value = future.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x00000097066A4AF0>, <Task finished name='Task-32' coro=<BaseTCPListener._handle_stream() done, defined at E:\Code\venv\lib\site-packages\distributed\comm\tcp.py:435> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\tcpserver.py", line 327, in <lambda>
    gen.convert_yielded(future), lambda f: f.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 444, in _handle_stream
    await self.comm_handler(comm)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 423, in handle_comm
    await comm.write(result, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x000000970D95BC10>, <Task finished name='Task-60386' coro=<BaseTCPListener._handle_stream() done, defined at E:\Code\venv\lib\site-packages\distributed\comm\tcp.py:435> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\tcpserver.py", line 327, in <lambda>
    gen.convert_yielded(future), lambda f: f.result()
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 444, in _handle_stream
    await self.comm_handler(comm)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 423, in handle_comm
    await comm.write(result, serializers=serializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000970417DB80>>, <Task finished name='Task-170779' coro=<Client._update_scheduler_info() done, defined at E:\Code\venv\lib\site-packages\distributed\client.py:1093> exception=MemoryError('Unable to allocate internal buffer.')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\client.py", line 1097, in _update_scheduler_info
    self._scheduler_identity = await self.scheduler.identity()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 757, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 538, in send_recv
    await comm.write(msg, serializers=serializers, on_error="raise")
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 226, in write
    frames = await to_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 49, in to_frames
    return _to_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 32, in _to_frames
    protocol.dumps(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 29, in dumps
    small_header, small_payload = dumps_msgpack(msg)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 157, in dumps_msgpack
    payload = msgpack.dumps(msg, use_bin_type=True)
  File "E:\Code\venv\lib\site-packages\msgpack\__init__.py", line 35, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack\_packer.pyx", line 114, in msgpack._cmsgpack.Packer.__cinit__
MemoryError: Unable to allocate internal buffer.
Traceback (most recent call last):
  File "E:\Code\Git\pipeline\code\main.py", line 70, in <module>
    df = adjust_sampling_frequency(df, v_dask=v_dask)
  File "E:\Code\Git\pipeline\code\monitoring\time_it.py", line 29, in wrap
    result = f(*args, **kw)
  File "E:\Code\Git\pipeline\code\data_cleansing\adjust_sampling_frequency.py", line 25, in adjust_sampling_frequency
    df = series_list_to_df(series_collection, df, v_dask)         
  File "E:\Code\Git\pipeline\code\tools\series_list_to_df.py", line 20, in series_list_to_df
    df = dask_repartition(df)
  File "E:\Code\Git\pipeline\code\monitoring\time_it.py", line 29, in wrap
    result = f(*args, **kw)
  File "E:\Code\Git\pipeline\code\tools\dask_repartition.py", line 8, in dask_repartition
    df = df.repartition(partition_size="100MB")
  File "E:\Code\venv\lib\site-packages\dask\dataframe\core.py", line 1172, in repartition
    return repartition_size(self, partition_size)
  File "E:\Code\venv\lib\site-packages\dask\dataframe\core.py", line 5803, in repartition_size
    mem_usages = df.map_partitions(total_mem_usage, deep=True).compute()
  File "E:\Code\venv\lib\site-packages\dask\base.py", line 166, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "E:\Code\venv\lib\site-packages\dask\base.py", line 444, in compute
    results = schedule(dsk, keys, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\client.py", line 2595, in get
    results = self.gather(packed, asynchronous=asynchronous, direct=direct)
  File "E:\Code\venv\lib\site-packages\distributed\client.py", line 1887, in gather
    return self.sync(
  File "E:\Code\venv\lib\site-packages\distributed\client.py", line 779, in sync
    return sync(
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 348, in sync
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 332, in f
distributed.core - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-80df29a596bdab7f2ebb939208bc315e', 34)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-80df29a596bdab7f2ebb939208bc315e', 34)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
    result[0] = yield future
  File "E:\Code\venv\lib\site-packages\tornado\gen.py", line 735, in run
    value = future.result()
  File "E:\Code\venv\lib\site-packages\distributed\client.py", line 1752, in _gather
distributed.worker - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-80df29a596bdab7f2ebb939208bc315e', 34)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-80df29a596bdab7f2ebb939208bc315e', 34)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
distributed.utils - ERROR - {'op': 'get_data', 'keys': ("('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-80df29a596bdab7f2ebb939208bc315e', 34)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-80df29a596bdab7f2ebb939208bc315e', 34)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000157D56FFD0>>, <Task finished name='Task-242915' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=AssertionError({'op': 'get_data', 'keys': ("('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-80df29a596bdab7f2ebb939208bc315e', 34)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True})>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 556, in send_recv
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 412, in handle_comm
    result = await result
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1250, in get_data
    assert response == "OK", response
AssertionError: {'op': 'get_data', 'keys': ("('repartition-merge-db938e1da6d2f2a592132126b20125bb', 401)", "('repartition-merge-80df29a596bdab7f2ebb939208bc315e', 34)"), 'who': 'tcp://127.0.0.1:59534', 'max_connections': None, 'reply': True}
    raise exception.with_traceback(traceback)
  File "E:\Code\venv\lib\site-packages\dask\dataframe\methods.py", line 101, in boundary_slice
    result = getattr(df, kind)[start:stop]
  File "E:\Code\venv\lib\site-packages\pandas\core\indexing.py", line 1768, in __getitem__
    return self._getitem_axis(maybe_callable, axis=axis)
distributed.protocol.core - CRITICAL - Failed to deserialize
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.worker - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

distributed.utils - ERROR - Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 665, in log_errors
    yield
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000157D56FFD0>>, <Task finished name='Task-243029' coro=<Worker.gather_dep() done, defined at E:\Code\venv\lib\site-packages\distributed\worker.py:1932> exception=TypeError('Could not serialize object of type DataFrame.\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 38, in dumps\n    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 191, in serialize\n    header, frames = dumps(x, context=context) if wants_context else dumps(x)\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\serialize.py", line 58, in pickle_dumps\n    return {"serializer": "pickle"}, [pickle.dumps(x)]\n  File "E:\\Code\\venv\\lib\\site-packages\\distributed\\protocol\\pickle.py", line 51, in dumps\n    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 62, in dumps\n    cp.dump(obj)\n  File "E:\\Code\\venv\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py", line 546, in dump\n    return Pickler.dump(self, obj)\nMemoryError\n')>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 1949, in gather_dep
    response = await get_data_from_worker(
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3219, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 386, in retry_operation
    return await retry(
  File "E:\Code\venv\lib\site-packages\distributed\utils_comm.py", line 379, in retry
    return await coro()
  File "E:\Code\venv\lib\site-packages\distributed\worker.py", line 3199, in _get_data
    response = await send_recv(
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 540, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\comm\tcp.py", line 211, in read
    msg = await from_frames(
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 75, in from_frames
    res = _from_frames()
  File "E:\Code\venv\lib\site-packages\distributed\comm\utils.py", line 60, in _from_frames
    return protocol.loads(
  File "E:\Code\venv\lib\site-packages\distributed\protocol\core.py", line 124, in loads
    value = _deserialize(head, fs, deserializers=deserializers)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 268, in deserialize
    return loads(header, frames)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 80, in serialization_error_loads
    raise TypeError(msg)
TypeError: Could not serialize object of type DataFrame.
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 191, in serialize
    header, frames = dumps(x, context=context) if wants_context else dumps(x)
  File "E:\Code\venv\lib\site-packages\distributed\protocol\serialize.py", line 58, in pickle_dumps
    return {"serializer": "pickle"}, [pickle.dumps(x)]
  File "E:\Code\venv\lib\site-packages\distributed\protocol\pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 62, in dumps
    cp.dump(obj)
  File "E:\Code\venv\lib\site-packages\cloudpickle\cloudpickle_fast.py", line 546, in dump
    return Pickler.dump(self, obj)
MemoryError

  File "E:\Code\venv\lib\site-packages\pandas\core\indexing.py", line 1912, in _getitem_axis
    return self._get_slice_axis(key, axis=axis)
  File "E:\Code\venv\lib\site-packages\pandas\core\indexing.py", line 1801, in _get_slice_axis
    return self._slice(indexer, axis=axis, kind="iloc")
  File "E:\Code\venv\lib\site-packages\pandas\core\indexing.py", line 631, in _slice
    return self.obj._slice(obj, axis=axis, kind=kind)
  File "E:\Code\venv\lib\site-packages\pandas\core\generic.py", line 3614, in _slice
    result = self._constructor(self._data.get_slice(slobj, axis=axis))
  File "E:\Code\venv\lib\site-packages\pandas\core\internals\managers.py", line 756, in get_slice
    bm._consolidate_inplace()
  File "E:\Code\venv\lib\site-packages\pandas\core\internals\managers.py", line 945, in _consolidate_inplace
    self.blocks = tuple(_consolidate(self.blocks))
  File "E:\Code\venv\lib\site-packages\pandas\core\internals\managers.py", line 1886, in _consolidate
    merged_blocks = _merge_blocks(
  File "E:\Code\venv\lib\site-packages\pandas\core\internals\blocks.py", line 3104, in _merge_blocks
    new_values = new_values[argsort]
MemoryError: Unable to allocate 3.20 MiB for an array with shape (10, 41897) and data type object
distributed.nanny - WARNING - Restarting worker
distributed.nanny - WARNING - Restarting worker
distributed.nanny - WARNING - Restarting worker
distributed.nanny - WARNING - Restarting worker
distributed.nanny - WARNING - Restarting worker
distributed.nanny - WARNING - Restarting worker
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x000000970417DB80>>, <Task finished name='Task-170876' coro=<SpecCluster._correct_state_internal() done, defined at E:\Code\venv\lib\site-packages\distributed\deploy\spec.py:300> exception=OSError("Timed out trying to connect to 'tcp://127.0.0.1:59489' after 10 s: Timed out trying to connect to 'tcp://127.0.0.1:59489' after 10 s: connect() didn't finish in time")>)
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 218, in connect
    _raise(error)
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 203, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://127.0.0.1:59489' after 10 s: connect() didn't finish in time

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\deploy\spec.py", line 381, in _close
    await self._correct_state()
  File "E:\Code\venv\lib\site-packages\distributed\deploy\spec.py", line 308, in _correct_state_internal
    await self.scheduler_comm.retire_workers(workers=list(to_close))
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 684, in send_recv_from_rpc
    comm = await self.live_comm()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 642, in live_comm
    comm = await connect(
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 227, in connect
    _raise(error)
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 203, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://127.0.0.1:59489' after 10 s: Timed out trying to connect to 'tcp://127.0.0.1:59489' after 10 s: connect() didn't finish in time
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 218, in connect
    _raise(error)
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 203, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://127.0.0.1:59489' after 10 s: connect() didn't finish in time

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 200, in ignoring
    yield
  File "E:\Code\venv\lib\site-packages\distributed\deploy\spec.py", line 607, in close_clusters
    cluster.close(timeout=10)
  File "E:\Code\venv\lib\site-packages\distributed\deploy\cluster.py", line 82, in close
    return self.sync(self._close, callback_timeout=timeout)
  File "E:\Code\venv\lib\site-packages\distributed\deploy\cluster.py", line 161, in sync
    return sync(self.loop, func, *args, **kwargs)
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 348, in sync
    raise exc.with_traceback(tb)
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 332, in f
    result[0] = yield future
  File "E:\Code\venv\lib\site-packages\tornado\gen.py", line 735, in run
    value = future.result()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 743, in _run_callback
    ret = callback()
  File "E:\Code\venv\lib\site-packages\tornado\ioloop.py", line 767, in _discard_future_result
    future.result()
  File "E:\Code\venv\lib\site-packages\distributed\deploy\spec.py", line 381, in _close
    await self._correct_state()
  File "E:\Code\venv\lib\site-packages\distributed\deploy\spec.py", line 308, in _correct_state_internal
    await self.scheduler_comm.retire_workers(workers=list(to_close))
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 684, in send_recv_from_rpc
    comm = await self.live_comm()
  File "E:\Code\venv\lib\site-packages\distributed\core.py", line 642, in live_comm
    comm = await connect(
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 227, in connect
    _raise(error)
  File "E:\Code\venv\lib\site-packages\distributed\comm\core.py", line 203, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://127.0.0.1:59489' after 10 s: Timed out trying to connect to 'tcp://127.0.0.1:59489' after 10 s: connect() didn't finish in time

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Programme\lib\contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "E:\Code\venv\lib\site-packages\distributed\utils.py", line 201, in ignoring
    except exceptions as e:
TypeError: catching classes that do not inherit from BaseException is not allowed
